{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict, List, Optional, Tuple, TypeVar, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch as th\n",
        "from gymnasium import spaces\n",
        "from torch import nn\n",
        "\n",
        "from stable_baselines3.common.distributions import Distribution"
      ],
      "metadata": {
        "id": "e7p18fU5sEuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "atLevur1tp2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# State Dependent Noise Distribution (gSDE) 🌵\n",
        "🪄 Distribution class for using generalized State Dependent Exploration (gSDE).\n",
        "\n",
        "Paper: https://arxiv.org/abs/2005.05719 🦄\n",
        "\n",
        "It is used to create the noise exploration matrix and compute the log probability of an action with that noise.\n",
        "\n",
        "   * :`param action_dim`: Dimension of the action space.\n",
        "   * :`param full_std:` Whether to use (n_features x n_actions) parameters for the std instead of only (n_features,)\n",
        "   * :`param use_expln:` Use `expln()` function instead of `exp()` to ensure a positive standard deviation (cf paper). It allows to keep variance above zero and prevent it from growing too fast. In practice, `exp()` is usually enough.\n",
        "   * `:param squash_output`: Whether to squash the output using a tanh function, this ensures bounds are satisfied.\n",
        "   \n",
        "   * `:param learn_features`: Whether to learn features for gSDE or not. This will enable gradients to be backpropagated through the features ``latent_sde`` in the code.\n",
        "\n",
        "   * `:param epsilon:` small value to avoid NaN due to numerical imprecision.\n",
        "    "
      ],
      "metadata": {
        "id": "QpCas8IfqVl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Needed class for gSDE 🎡\n",
        "The **TanhBijector** class defines a bijective transformation using the hyperbolic tangent function (tanh). This class is often used in reinforcement learning algorithms to squash the output of the policy network to ensure that the actions remain within a specific range, typically [-1,1]"
      ],
      "metadata": {
        "id": "tEvfivo6tp4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TanhBijector:\n",
        "    \"\"\"\n",
        "    Bijective transformation of a probability distribution\n",
        "    using a squashing function (tanh)\n",
        "\n",
        "    :param epsilon: small value to avoid NaN due to numerical imprecision.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon: float = 1e-6):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(x: th.Tensor) -> th.Tensor:\n",
        "        return th.tanh(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def atanh(x: th.Tensor) -> th.Tensor:\n",
        "        \"\"\"\n",
        "        Inverse of Tanh\n",
        "\n",
        "        Taken from Pyro: https://github.com/pyro-ppl/pyro\n",
        "        0.5 * torch.log((1 + x ) / (1 - x))\n",
        "        \"\"\"\n",
        "        return 0.5 * (x.log1p() - (-x).log1p())\n",
        "\n",
        "    @staticmethod\n",
        "    def inverse(y: th.Tensor) -> th.Tensor:\n",
        "        \"\"\"\n",
        "        Inverse tanh.\n",
        "\n",
        "        :param y:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        eps = th.finfo(y.dtype).eps\n",
        "        # Clip the action to avoid NaN\n",
        "        return TanhBijector.atanh(y.clamp(min=-1.0 + eps, max=1.0 - eps))\n",
        "\n",
        "    def log_prob_correction(self, x: th.Tensor) -> th.Tensor:\n",
        "        # Squash correction (from original SAC implementation)\n",
        "        return th.log(1.0 - th.tanh(x) ** 2 + self.epsilon)\n",
        "\n"
      ],
      "metadata": {
        "id": "BAn7aBUFuFWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gSDE class 🐧"
      ],
      "metadata": {
        "id": "Lmy9PbVwuNGN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHZqJRpgp4yJ"
      },
      "outputs": [],
      "source": [
        "class gSDE(Distribution):\n",
        "    bijector: Optional[\"TanhBijector\"]\n",
        "    latent_sde_dim: Optional[int]\n",
        "    weights_dist: Normal\n",
        "    _latent_sde: th.Tensor\n",
        "    exploration_mat: th.Tensor\n",
        "    exploration_matrices: th.Tensor\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        action_dim: int,\n",
        "        full_std: bool = True,\n",
        "        use_expln: bool = False,\n",
        "        squash_output: bool = False,\n",
        "        learn_features: bool = False,\n",
        "        epsilon: float = 1e-6,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.action_dim = action_dim\n",
        "        self.latent_sde_dim = None\n",
        "        self.mean_actions = None #get from nn\n",
        "        self.log_std = None #get from NN\n",
        "        self.use_expln = use_expln\n",
        "        self.full_std = full_std\n",
        "        self.epsilon = epsilon\n",
        "        self.learn_features = learn_features\n",
        "        if squash_output:\n",
        "            self.bijector = TanhBijector(epsilon)\n",
        "        else:\n",
        "            self.bijector = None\n",
        "\n",
        "    #-------------------------------------------- get actions ------------------------------------------------------\n",
        "    def get_std(self, log_std: th.Tensor) -> th.Tensor:\n",
        "        \"\"\"\n",
        "        Get the standard deviation from the learned parameter\n",
        "        (log of it by default). This ensures that the std is positive.\n",
        "\n",
        "        :param log_std:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if self.use_expln:\n",
        "            # From gSDE paper, it allows to keep variance\n",
        "            # above zero and prevent it from growing too fast\n",
        "            below_threshold = th.exp(log_std) * (log_std <= 0)\n",
        "            # Avoid NaN: zeros values that are below zero\n",
        "            safe_log_std = log_std * (log_std > 0) + self.epsilon\n",
        "            above_threshold = (th.log1p(safe_log_std) + 1.0) * (log_std > 0)\n",
        "            std = below_threshold + above_threshold\n",
        "        else:\n",
        "            # Use normal exponential\n",
        "            std = th.exp(log_std)\n",
        "\n",
        "        if self.full_std:\n",
        "            return std\n",
        "        assert self.latent_sde_dim is not None\n",
        "        # Reduce the number of parameters:\n",
        "        return th.ones(self.latent_sde_dim, self.action_dim).to(log_std.device) * std\n",
        "\n",
        "\n",
        "\n",
        "    def sample_weights(self, log_std: th.Tensor, batch_size: int = 1)-> th.Tensor:\n",
        "      \"\"\"\n",
        "      Sample weights for the noise exploration matrix,\n",
        "      using a centered Gaussian distribution.\n",
        "\n",
        "      :param log_std:\n",
        "      :param batch_size:\n",
        "      \"\"\"\n",
        "      std = self.get_std(log_std)\n",
        "      self.weights_dist = Normal(th.zeros_like(std), std)\n",
        "      # Reparametrization trick to pass gradients\n",
        "      self.exploration_mat = self.weights_dist.rsample()\n",
        "      # Pre-compute matrices in case of parallel exploration\n",
        "      exploration_matrices = self.weights_dist.rsample((batch_size,))\n",
        "      return exploration_matrices\n",
        "\n",
        "    def get_noise(self, latent_sde: th.Tensor) -> th.Tensor:\n",
        "        self.exploration_matrices = self.sample_weights(log_std)\n",
        "        latent_sde = latent_sde if self.learn_features else latent_sde.detach()\n",
        "        # Default case: only one exploration matrix\n",
        "        if len(latent_sde) == 1 or len(latent_sde) != len(self.exploration_matrices):\n",
        "            return th.mm(latent_sde, self.exploration_mat)\n",
        "        # Use batch matrix multiplication for efficient computation\n",
        "        # (batch_size, n_features) -> (batch_size, 1, n_features)\n",
        "        latent_sde = latent_sde.unsqueeze(dim=1)\n",
        "        # (batch_size, 1, n_actions)\n",
        "        noise = th.bmm(latent_sde, self.exploration_matrices)\n",
        "        return noise.squeeze(dim=1)\n",
        "\n",
        "\n",
        "    def get_distribution(\n",
        "        self: gSDE, mean_actions: th.Tensor, log_std: th.Tensor, latent_sde: th.Tensor\n",
        "    ) -> th.Tensor:\n",
        "        \"\"\"\n",
        "        Create the distribution given its parameters (mean, std)\n",
        "\n",
        "        :param mean_actions:\n",
        "        :param log_std:\n",
        "        :param latent_sde:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # Stop gradient if we don't want to influence the features\n",
        "        self._latent_sde = latent_sde if self.learn_features else latent_sde.detach()\n",
        "        variance = th.mm(self._latent_sde**2, self.get_std(log_std) ** 2)\n",
        "        distribution = Normal(mean_actions, th.sqrt(variance + self.epsilon))\n",
        "        return distribution\n",
        "\n",
        "    #get action\n",
        "    def sample(self) -> th.Tensor:\n",
        "        noise = self.get_noise(self._latent_sde)\n",
        "        self.distribution = get_distribution(self.mean_actions, self.log_std, latent_sde)\n",
        "        actions = self.distribution.mean + noise\n",
        "        if self.bijector is not None:\n",
        "            return self.bijector.forward(actions)\n",
        "        return actions\n",
        "\n",
        "# --------------------------------------------- logprobs and entropy --------------------------------------------\n",
        "#to be both called after self.sample, otherwise self.distribution wuold be Nan and you get nothing\n",
        "\n",
        "    def log_prob(self, actions: th.Tensor) -> th.Tensor:\n",
        "        if self.bijector is not None:\n",
        "            gaussian_actions = self.bijector.inverse(actions)\n",
        "        else:\n",
        "            gaussian_actions = actions\n",
        "        # log likelihood for a gaussian\n",
        "        log_prob = self.distribution.log_prob(gaussian_actions)\n",
        "        # Sum along action dim\n",
        "        log_prob = sum_independent_dims(log_prob)\n",
        "\n",
        "        if self.bijector is not None:\n",
        "            # Squash correction (from original SAC implementation)\n",
        "            log_prob -= th.sum(self.bijector.log_prob_correction(gaussian_actions), dim=1)\n",
        "        return log_prob\n",
        "\n",
        "    def entropy(self) -> Optional[th.Tensor]:\n",
        "        if self.bijector is not None:\n",
        "            # No analytical form,\n",
        "            # entropy needs to be estimated using -log_prob.mean()\n",
        "            return None\n",
        "        return sum_independent_dims(self.distribution.entropy())\n",
        "\n",
        "\n",
        "# ---------------------------------------------- auxiliary functions  ------------------------------------------------\n",
        "#not stricly needed for my PPO. Might still be useful, so keep them\n",
        "    def mode(self) -> th.Tensor:\n",
        "        actions = self.distribution.mean\n",
        "        if self.bijector is not None:\n",
        "            return self.bijector.forward(actions)\n",
        "        return actions\n",
        "\n",
        "    def actions_from_params(\n",
        "        self, mean_actions: th.Tensor, log_std: th.Tensor, latent_sde: th.Tensor, deterministic: bool = False\n",
        "    ) -> th.Tensor:\n",
        "        # Update the proba distribution\n",
        "        self.proba_distribution(mean_actions, log_std, latent_sde)\n",
        "        return self.get_actions(deterministic=deterministic)\n",
        "\n",
        "    def log_prob_from_params(\n",
        "        self, mean_actions: th.Tensor, log_std: th.Tensor, latent_sde: th.Tensor\n",
        "    ) -> Tuple[th.Tensor, th.Tensor]:\n",
        "        actions = self.actions_from_params(mean_actions, log_std, latent_sde)\n",
        "        log_prob = self.log_prob(actions)\n",
        "        return actions, log_prob\n",
        "\n"
      ]
    }
  ]
}